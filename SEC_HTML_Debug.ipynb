import requests
from bs4 import BeautifulSoup
import re
import os

# Sample URL to test with (use real SEC EDGAR URLs)
urls = [
    "https://www.sec.gov/Archives/edgar/data/320193/000032019319000119/a10-k20199292019.htm"
]

def download_filing(url, save_path):
    response = requests.get(url)
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(response.text)

def extract_relevant_sections(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Debug: Print the raw HTML to check structure
    print(content[:5000])  # Print the first 5000 characters

    soup = BeautifulSoup(content, 'html.parser')
    
    # Extract Management's Discussion and Analysis (you can refine this as needed)
    mda = soup.find('a', {'name': re.compile('mda', re.I)})
    mda_text = ""
    if mda:
        mda_section = mda.find_next('div', {'class': 'section'})
        if mda_section:
            mda_text = mda_section.get_text()

    # Extract Risk Factors (you can refine this as needed)
    risk = soup.find('a', {'name': re.compile('risk', re.I)})
    risk_text = ""
    if risk:
        risk_section = risk.find_next('div', {'class': 'section'})
        if risk_section:
            risk_text = risk_section.get_text()

    return mda_text + "\n\n" + risk_text

def main():
    # Test with one URL for debugging
    url = urls[0]
    file_name = url.split('/')[-1]
    save_path = file_name
    
    # Download and save the filing
    download_filing(url, save_path)

    # Extract relevant sections and print them
    extracted_text = extract_relevant_sections(save_path)
    print("Extracted Text:\n", extracted_text[:1000])  # Print the first 1000 characters of extracted text

if __name__ == "__main__":
    main()
